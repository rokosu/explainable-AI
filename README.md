# explainable-AI
This study explores the use of explainable AI (XAI) to optimise portfolios using a model-agnostic approach and the use of SHAPs. Using historical Apple Inc. (AAPL) data, we evaluate the interpretability and performance of random forest models, gradient boosting machines, and neural nets. 
Our findings show that closing prices and volume consistently drive portfolio returns, which is in line with established financial theory. SHAP dependence plots reveal nonlinear relationships, particularly with a 50-day moving average, which is an advantage in understanding model dynamics. Research shows that there is a clear trade-off between risk and reward, Random Forest gets higher returns but larger losses, while the neural net provides better risk management. SHAP force maps provide a transparent view of the individual predictions. Sociological interpretations, informed by theories of crime, complete the analysis. This research provides practical implications for portfolio managers and regulators and highlights the importance of using artificial intelligence in finance in order to promote the uptake of AI in an informed and responsible way.
